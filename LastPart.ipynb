{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 128 Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement this part of face recognition, we need to import some specific packages. [Dlib](https://pypi.org/project/dlib) is a modern C++ toolkit containing machine learning algorithms and tools for creating complex software in C++ to solve real world problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the path of our project. Under the path, we have different files to save images, neural network model, face data of measurements and landmarks. You can build corresponding file path on your laptop and put the code, images, data in these files. After we build our path successfully, we can input our images, famous people`s photo is better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mac/7390/Final\n"
     ]
    }
   ],
   "source": [
    "current_path = os.getcwd()  # get current path\n",
    "print (current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will import and load neural network of project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of model\n",
    "predictor_path = current_path + \"/model/shape_predictor_68_face_landmarks (1).dat\"\n",
    "face_rec_model_path = current_path + \"/model/dlib_face_recognition_resnet_model_v1.dat\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test images` path\n",
    "faces_folder_path = current_path + \"/faces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and input model\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "shape_predictor = dlib.shape_predictor(predictor_path)\n",
    "face_rec_model = dlib.face_recognition_model_v1(face_rec_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we convert image from BGR format to RGB format because we do not need the colored data to detect faces. Humans can easily recognize that both images are the same, but the computer thinks these two pictures are two completely different people. To solve this, we will try to distort each image so that the eyes and lips are always in the sample place in the image. This will make it easier to compare the differences between faces in the next steps.\n",
    "To do this, we'll use an algorithm called face landmark estimation. There are many ways to do this, but this time we will use a method invented by Vahid Kazemi and Josephine Sullivan in 2014. The basic idea of this algorithm is to find 68 people face the prevalence of particular point (called feature points, the landmarks), including the top of the jaw, external contours of each eye, each internal contours of the eyebrows, etc. Next the program trains a machine learning algorithm that allows it to find 68 specific points in any face. We will place 68 feature points on each face. \n",
    "\n",
    "\n",
    "After we get 68 landmarks of face, we need to extract some basic measurements from each person's face. Then we can measure the unknown face in the same way and find the known face closest to the measurement. For example, we can measure the size of each ear, the distance between the eyes, the length of the nose, and so on. So the code is to train a deep convolutional neural network. However, it's not about identifying objects in the picture, and this time we're training it to generate 128 measurements for the face. And by comparing the 128 measurements from different images, we can find difference and get the same image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/mac/7390/Final/faces/Emma.jpg\n",
      "Number of faces detected: 1\n",
      "face 0; left 91; top 246; right 553; bottom 708\n",
      "-0.161305\n",
      "0.0652001\n",
      "0.0167216\n",
      "-0.0874412\n",
      "-0.115376\n",
      "-0.0352147\n",
      "-0.038751\n",
      "-0.090691\n",
      "0.14881\n",
      "-0.177061\n",
      "0.169819\n",
      "-0.0652394\n",
      "-0.322522\n",
      "0.047483\n",
      "-0.0544668\n",
      "0.145439\n",
      "-0.193972\n",
      "-0.122037\n",
      "-0.0631586\n",
      "-0.121744\n",
      "0.0135362\n",
      "0.0828123\n",
      "0.0114669\n",
      "0.104588\n",
      "-0.140688\n",
      "-0.300228\n",
      "-0.1491\n",
      "-0.101557\n",
      "-0.128877\n",
      "-0.0805732\n",
      "0.0602865\n",
      "0.0722952\n",
      "-0.0997832\n",
      "0.0112618\n",
      "0.0747684\n",
      "0.109706\n",
      "-0.0203456\n",
      "-0.08323\n",
      "0.244281\n",
      "-0.0157787\n",
      "-0.169955\n",
      "-0.00907224\n",
      "0.205865\n",
      "0.329943\n",
      "0.268684\n",
      "-0.00828258\n",
      "-0.0172921\n",
      "-0.00430323\n",
      "0.195417\n",
      "-0.326387\n",
      "0.0101277\n",
      "0.15433\n",
      "0.157005\n",
      "0.031648\n",
      "0.131255\n",
      "-0.135116\n",
      "0.00602079\n",
      "0.235568\n",
      "-0.196762\n",
      "0.0424563\n",
      "0.0663703\n",
      "-0.110236\n",
      "0.0176481\n",
      "0.000920264\n",
      "0.295794\n",
      "0.0458768\n",
      "-0.232505\n",
      "-0.0782014\n",
      "0.232061\n",
      "-0.219089\n",
      "-0.0108243\n",
      "0.126979\n",
      "-0.167734\n",
      "-0.276375\n",
      "-0.222794\n",
      "0.0883816\n",
      "0.380695\n",
      "0.177336\n",
      "-0.0315785\n",
      "0.114273\n",
      "-0.0640652\n",
      "-0.0391783\n",
      "-0.0791077\n",
      "0.131224\n",
      "-0.0576154\n",
      "-0.0402545\n",
      "-0.0810987\n",
      "0.0626532\n",
      "0.263068\n",
      "0.0104699\n",
      "0.0103405\n",
      "0.330588\n",
      "0.0190853\n",
      "-0.0675295\n",
      "0.0356764\n",
      "0.0264795\n",
      "-0.114388\n",
      "-0.136609\n",
      "-0.168926\n",
      "0.0195078\n",
      "-0.064789\n",
      "-0.143866\n",
      "-0.0322042\n",
      "0.0901518\n",
      "-0.241458\n",
      "0.0996762\n",
      "-0.110076\n",
      "-0.0825996\n",
      "-0.144195\n",
      "-0.0734498\n",
      "-0.0928666\n",
      "0.0400913\n",
      "0.18994\n",
      "-0.348377\n",
      "0.0582386\n",
      "0.127153\n",
      "0.0533892\n",
      "0.189228\n",
      "0.0294154\n",
      "0.0149846\n",
      "0.0584215\n",
      "-0.0857043\n",
      "-0.146356\n",
      "-0.112269\n",
      "0.0745371\n",
      "-0.0521986\n",
      "0.0834123\n",
      "0.0196596\n",
      "Processing file: /Users/mac/7390/Final/faces/Emma1.jpg\n",
      "Number of faces detected: 1\n",
      "face 0; left 498; top 290; right 765; bottom 558\n",
      "-0.124562\n",
      "0.137016\n",
      "-0.0181006\n",
      "-0.0509651\n",
      "-0.180834\n",
      "0.0522183\n",
      "-0.0230608\n",
      "-0.0990563\n",
      "0.180686\n",
      "-0.18775\n",
      "0.157342\n",
      "-0.0702309\n",
      "-0.359208\n",
      "-0.000745736\n",
      "-0.0605863\n",
      "0.238312\n",
      "-0.270155\n",
      "-0.178679\n",
      "-0.110776\n",
      "-0.163993\n",
      "0.0415428\n",
      "0.0579523\n",
      "0.0915786\n",
      "0.132185\n",
      "-0.188084\n",
      "-0.345015\n",
      "-0.0394308\n",
      "-0.147195\n",
      "-0.0879748\n",
      "-0.1665\n",
      "0.0676807\n",
      "0.0724267\n",
      "-0.0980317\n",
      "0.0802238\n",
      "0.00523642\n",
      "0.130535\n",
      "-0.0546172\n",
      "-0.189164\n",
      "0.251394\n",
      "0.0187969\n",
      "-0.198718\n",
      "-0.0287524\n",
      "0.180379\n",
      "0.317373\n",
      "0.244958\n",
      "-0.0817903\n",
      "0.0278203\n",
      "-0.0254568\n",
      "0.227452\n",
      "-0.354045\n",
      "0.0480731\n",
      "0.149089\n",
      "0.112182\n",
      "0.0854134\n",
      "0.165965\n",
      "-0.16327\n",
      "0.0290111\n",
      "0.206408\n",
      "-0.170885\n",
      "0.0494696\n",
      "0.0895616\n",
      "-0.0810165\n",
      "0.0235901\n",
      "-0.0436149\n",
      "0.292879\n",
      "0.0861598\n",
      "-0.172595\n",
      "-0.10295\n",
      "0.186597\n",
      "-0.153841\n",
      "-0.0737533\n",
      "0.154661\n",
      "-0.175415\n",
      "-0.247213\n",
      "-0.228675\n",
      "0.0677619\n",
      "0.418521\n",
      "0.216718\n",
      "-0.0147959\n",
      "0.0379493\n",
      "-0.0619064\n",
      "-0.0534043\n",
      "-0.0838951\n",
      "0.163671\n",
      "-0.04719\n",
      "-0.0672829\n",
      "-0.133999\n",
      "0.134838\n",
      "0.234404\n",
      "-0.0289913\n",
      "-0.0574508\n",
      "0.339637\n",
      "0.035548\n",
      "-0.088619\n",
      "-0.014886\n",
      "0.0199197\n",
      "-0.178802\n",
      "-0.0282365\n",
      "-0.127411\n",
      "-0.0480409\n",
      "0.0051009\n",
      "-0.123385\n",
      "-0.0361877\n",
      "0.0175102\n",
      "-0.194745\n",
      "0.0889645\n",
      "-0.0942884\n",
      "-0.0567937\n",
      "-0.106283\n",
      "-0.0647526\n",
      "-0.163784\n",
      "0.0949369\n",
      "0.195364\n",
      "-0.336351\n",
      "0.137217\n",
      "0.144584\n",
      "0.12208\n",
      "0.176115\n",
      "0.0603051\n",
      "0.0423299\n",
      "0.0575203\n",
      "-0.118003\n",
      "-0.129545\n",
      "-0.0860705\n",
      "0.0921739\n",
      "-0.0148692\n",
      "0.0585406\n",
      "0.0516515\n",
      "Processing file: /Users/mac/7390/Final/faces/Kerr.jpg\n",
      "Number of faces detected: 1\n",
      "face 0; left 118; top 139; right 304; bottom 325\n",
      "-0.0837487\n",
      "0.118646\n",
      "0.105285\n",
      "-0.0492605\n",
      "-0.127783\n",
      "-0.0671275\n",
      "-0.0225206\n",
      "-0.119219\n",
      "0.198321\n",
      "-0.0735956\n",
      "0.0961106\n",
      "0.0131965\n",
      "-0.132195\n",
      "0.0519337\n",
      "-0.0500163\n",
      "0.152836\n",
      "-0.108617\n",
      "-0.217806\n",
      "-0.00417404\n",
      "-0.0564184\n",
      "0.135643\n",
      "0.001893\n",
      "-0.0660213\n",
      "0.13742\n",
      "-0.223513\n",
      "-0.214826\n",
      "-0.139979\n",
      "-0.027672\n",
      "-0.169333\n",
      "-0.0785345\n",
      "0.0562492\n",
      "0.17635\n",
      "-0.145202\n",
      "0.0353365\n",
      "-0.0103967\n",
      "0.0853893\n",
      "-0.0280707\n",
      "-0.0965821\n",
      "0.20583\n",
      "0.13108\n",
      "-0.252295\n",
      "-0.0169901\n",
      "0.0921501\n",
      "0.318849\n",
      "0.222276\n",
      "-0.0511469\n",
      "0.0289156\n",
      "0.0109019\n",
      "0.141276\n",
      "-0.291215\n",
      "0.0173255\n",
      "0.237675\n",
      "0.0380797\n",
      "0.0929819\n",
      "0.0879254\n",
      "-0.0872204\n",
      "0.0417673\n",
      "0.0362363\n",
      "-0.203596\n",
      "0.0232666\n",
      "0.0781862\n",
      "-0.191718\n",
      "-0.0362534\n",
      "-0.175281\n",
      "0.126604\n",
      "0.191968\n",
      "-0.0617644\n",
      "-0.131982\n",
      "0.195464\n",
      "-0.172161\n",
      "-0.171476\n",
      "0.0824346\n",
      "-0.176523\n",
      "-0.197158\n",
      "-0.269924\n",
      "-0.00249415\n",
      "0.437119\n",
      "0.186304\n",
      "-0.136308\n",
      "0.065742\n",
      "-0.027086\n",
      "-0.0590116\n",
      "0.0122122\n",
      "0.156262\n",
      "0.0723838\n",
      "0.0332207\n",
      "-0.0640606\n",
      "0.0808363\n",
      "0.251721\n",
      "-0.00839377\n",
      "-0.0127509\n",
      "0.234405\n",
      "0.0346238\n",
      "-0.0326371\n",
      "-0.0156421\n",
      "0.0369475\n",
      "-0.0357871\n",
      "0.0533449\n",
      "-0.14185\n",
      "0.0366565\n",
      "-0.110963\n",
      "0.00311289\n",
      "-0.0381141\n",
      "0.0836999\n",
      "-0.164809\n",
      "0.175618\n",
      "0.0305772\n",
      "-0.0437037\n",
      "-0.198862\n",
      "-0.0194914\n",
      "-0.144933\n",
      "0.0257901\n",
      "0.12606\n",
      "-0.208298\n",
      "0.0966383\n",
      "0.107818\n",
      "-0.0528953\n",
      "0.0853398\n",
      "-0.0247761\n",
      "0.115382\n",
      "-0.0135532\n",
      "-0.119679\n",
      "-0.139519\n",
      "-0.0599277\n",
      "0.0549945\n",
      "-0.0282298\n",
      "-0.011262\n",
      "0.0603163\n",
      "Processing file: /Users/mac/7390/Final/faces/kerr1.jpg\n",
      "Number of faces detected: 1\n",
      "face 0; left 266; top 93; right 489; bottom 316\n",
      "-0.142779\n",
      "0.133359\n",
      "0.0705778\n",
      "-0.0553389\n",
      "-0.175272\n",
      "-0.0768457\n",
      "-0.0394243\n",
      "-0.127365\n",
      "0.199806\n",
      "-0.0970728\n",
      "0.0919133\n",
      "-0.0421761\n",
      "-0.148557\n",
      "0.0377748\n",
      "-0.0339878\n",
      "0.144191\n",
      "-0.128585\n",
      "-0.239029\n",
      "0.002884\n",
      "-0.0445254\n",
      "0.137665\n",
      "-0.0336372\n",
      "-0.107139\n",
      "0.169164\n",
      "-0.20689\n",
      "-0.250256\n",
      "-0.133538\n",
      "-0.0391113\n",
      "-0.115792\n",
      "-0.106785\n",
      "0.0573565\n",
      "0.172291\n",
      "-0.146014\n",
      "0.0231116\n",
      "-0.00960758\n",
      "0.0972138\n",
      "0.0206227\n",
      "-0.100649\n",
      "0.143007\n",
      "0.0172201\n",
      "-0.292468\n",
      "-0.0963142\n",
      "0.140686\n",
      "0.298895\n",
      "0.210024\n",
      "-0.0519883\n",
      "-0.0357496\n",
      "0.023289\n",
      "0.188446\n",
      "-0.264679\n",
      "-0.0532904\n",
      "0.230156\n",
      "0.0485503\n",
      "0.124439\n",
      "0.108892\n",
      "-0.113827\n",
      "0.100192\n",
      "0.0502444\n",
      "-0.200138\n",
      "0.00196894\n",
      "0.071085\n",
      "-0.23267\n",
      "-0.0240219\n",
      "-0.182856\n",
      "0.14223\n",
      "0.17089\n",
      "-0.0572585\n",
      "-0.152557\n",
      "0.156507\n",
      "-0.173525\n",
      "-0.144773\n",
      "0.0758181\n",
      "-0.168467\n",
      "-0.191368\n",
      "-0.287978\n",
      "-0.0219838\n",
      "0.365554\n",
      "0.214765\n",
      "-0.128071\n",
      "0.0954701\n",
      "0.0160618\n",
      "-0.00870413\n",
      "0.0125589\n",
      "0.125017\n",
      "0.0193275\n",
      "0.0303416\n",
      "-0.104719\n",
      "0.0775338\n",
      "0.221681\n",
      "-0.0166535\n",
      "0.0531206\n",
      "0.204448\n",
      "-0.0309983\n",
      "-0.0236222\n",
      "-0.0157225\n",
      "0.0755541\n",
      "-0.104971\n",
      "0.0735229\n",
      "-0.113672\n",
      "0.0534751\n",
      "-0.00107577\n",
      "-0.0303227\n",
      "0.00408721\n",
      "0.0852414\n",
      "-0.170732\n",
      "0.138784\n",
      "0.017343\n",
      "0.0216633\n",
      "-0.170879\n",
      "-0.0162196\n",
      "-0.121174\n",
      "0.0404945\n",
      "0.115256\n",
      "-0.197637\n",
      "0.175469\n",
      "0.0970571\n",
      "-0.0771531\n",
      "0.103864\n",
      "-0.00623441\n",
      "0.105396\n",
      "-0.0541921\n",
      "-0.130746\n",
      "-0.0972468\n",
      "-0.071703\n",
      "0.0771198\n",
      "-0.061159\n",
      "-0.027995\n",
      "0.023661\n"
     ]
    }
   ],
   "source": [
    "for img_path in glob.glob(os.path.join(faces_folder_path, \"*.jpg\")):\n",
    "    print(\"Processing file: {}\".format(img_path))\n",
    "    # opencv read the image and display\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    # opencv convert image from BGR format to RGB format\n",
    "    b, g, r = cv2.split(img)\n",
    "    img2 = cv2.merge([r, g, b])\n",
    "    dets = detector(img, 1)   # calibrat face\n",
    "    print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "\n",
    "    for index, face in enumerate(dets):\n",
    "        print('face {}; left {}; top {}; right {}; bottom {}'.format(index, face.left(), face.top(), face.right(), face.bottom()))\n",
    "\n",
    "        shape = shape_predictor(img2, face)   # capture 68 landmarks of face\n",
    "        for i, pt in enumerate(shape.parts()):\n",
    "            #print('Part {}: {}'.format(i, pt))\n",
    "            pt_pos = (pt.x, pt.y)\n",
    "            cv2.circle(img, pt_pos, 2, (255, 0, 0), 1)\n",
    "            #print(type(pt))\n",
    "        #print(\"Part 0: {}, Part 1: {} ...\".format(shape.part(0), shape.part(1)))\n",
    "        cv2.namedWindow(img_path+str(index), cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow(img_path+str(index), img)\n",
    "\n",
    "        face_descriptor = face_rec_model.compute_face_descriptor(img2, shape)   # calculate 128 vectors of face\n",
    "        print(face_descriptor)\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of code, we define a function for after use to compare two images. The paramter data1 and data2 are 128 vectors value of two images and we use euclidean distance to find the difference of two images. If the difference is higner than 0.6, they are not the same person. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparePersonData(data1, data2):\n",
    "    diff = 0\n",
    "    # for v1, v2 in data1, data2:\n",
    "        # diff += (v1 - v2)**2\n",
    "    for i in range(len(data1)):\n",
    "        diff += (data1[i] - data2[i])**2\n",
    "    diff = np.sqrt(diff)\n",
    "    print (diff)\n",
    "    if(diff < 0.6):\n",
    "        print (\"It's the same person\")\n",
    "    else:\n",
    "        print (\"It's not the same person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the 128 vectors of each image for future comapre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePersonData(face_rec_class, face_descriptor):\n",
    "    if face_rec_class.name == None or face_descriptor == None:\n",
    "        return\n",
    "    filePath = face_rec_class.dataPath + face_rec_class.name + '.npy'\n",
    "    vectors = np.array([])\n",
    "    for i, num in enumerate(face_descriptor):\n",
    "        vectors = np.append(vectors, num)\n",
    "        # print(num)\n",
    "    print('Saving files to :'+filePath)\n",
    "    \n",
    "    np.save(filePath, vectors)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the face images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPersonData(face_rec_class, personName):\n",
    "    if personName == None:\n",
    "        return\n",
    "    filePath = face_rec_class.dataPath + personName + '.npy'\n",
    "    vectors = np.load(filePath)\n",
    "    print(vectors)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the main class of code and initialize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class face_recognition(object):\n",
    "    def __init__(self):\n",
    "        self.current_path = os.getcwd() # get current path\n",
    "        self.predictor_path = self.current_path + \"/model/shape_predictor_68_face_landmarks (1).dat\"\n",
    "        self.face_rec_model_path = self.current_path + \"/model/dlib_face_recognition_resnet_model_v1.dat\"\n",
    "        self.faces_folder_path = self.current_path + \"/faces\"\n",
    "        self.dataPath = self.current_path + \"/data/\"\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        self.shape_predictor = dlib.shape_predictor(self.predictor_path)\n",
    "        self.face_rec_model = dlib.face_recognition_model_v1(self.face_rec_model_path)\n",
    "\n",
    "        self.name = None\n",
    "        self.img_bgr = None\n",
    "        self.img_rgb = None\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        self.shape_predictor = dlib.shape_predictor(self.predictor_path)\n",
    "        self.face_rec_model = dlib.face_recognition_model_v1(self.face_rec_model_path)\n",
    "\n",
    "    def inputPerson(self, name='people', img_path=None):\n",
    "        if img_path == None:\n",
    "            print('No file!\\n')\n",
    "            return \n",
    "\n",
    "        # img_name += self.faces_folder_path + img_name\n",
    "        self.name = name\n",
    "        self.img_bgr = cv2.imread(self.current_path+img_path)\n",
    "        # opencv convert image from BGR format to RGB format\n",
    "        b, g, r = cv2.split(self.img_bgr)\n",
    "        self.img_rgb = cv2.merge([r, g, b])\n",
    "\n",
    "    def create128DVectorSpace(self):\n",
    "        dets = self.detector(self.img_rgb, 1)\n",
    "        print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "        for index, face in enumerate(dets):\n",
    "            print('face {}; left {}; top {}; right {}; bottom {}'.format(index, face.left(), face.top(), face.right(), face.bottom()))\n",
    "\n",
    "            shape = self.shape_predictor(self.img_rgb, face)\n",
    "            face_descriptor = self.face_rec_model.compute_face_descriptor(self.img_rgb, shape)\n",
    "            # print(face_descriptor)\n",
    "            # for i, num in enumerate(face_descriptor):\n",
    "            #   print(num)\n",
    "            #   print(type(num))\n",
    "\n",
    "            return face_descriptor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n",
      "face 0; left 91; top 246; right 553; bottom 708\n",
      "Saving files to :/Users/mac/7390/Final/data/Emma.npy\n"
     ]
    }
   ],
   "source": [
    "face_rec = face_recognition()   # create object\n",
    "face_rec.inputPerson(name=\"Emma\", img_path=\"/faces/Emma.jpg\")  # name中写第一个人名字，img_name为图片名字，注意要放在faces文件夹中\n",
    "vector = face_rec.create128DVectorSpace()  # extract the 128-dimensional vector, which is the object of the dlib.vector class.\n",
    "person_data1 = savePersonData(face_rec, vector )   # save the extracted data to data file，it is used to return numpy array，context is same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n",
      "face 0; left 266; top 93; right 489; bottom 316\n",
      "Saving files to :/Users/mac/7390/Final/dataKerr.npy\n"
     ]
    }
   ],
   "source": [
    "# input the second image and extract feature vectors \n",
    "face_rec.inputPerson(name='Kerr', img_path='/faces/Kerr1.jpg')\n",
    "vector = face_rec.create128DVectorSpace()  # extract 128 vectors，which is the object of the dlib.vector class\n",
    "person_data2 = savePersonData(face_rec, vector )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869438026398012\n",
      "It's not the same person\n"
     ]
    }
   ],
   "source": [
    "# calculate euclidean distance and judge if they are the same people\n",
    "comparePersonData(person_data1, person_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
