{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hog Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of recognition find all faces in the picture by face detection. Such as iPhones camera application. In this project, we use Histogram of Oriented Gradients (HOG) method. The principle behind the Hog: \n",
    "     1.we need to convert rgb picture to black and white. 2.Then we'll look at each pixel in the image. For a single pixel, we also look at the other pixels around it. 3.Our goal is to find the pixel directly. And then we're going to draw an arrow that's going to indicate the direction that the image is going to go dark. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dlib\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use the dlib's face_detector which has the fuction of Hog face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 faces in the file /Users/mac/7390/Final/faces/Emma.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_name = '/Users/mac/7390/Final/faces/Emma.jpg'\n",
    "# Create a HOG face detector using the built-in dlib class\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "win = dlib.image_window()\n",
    "# Load the image into an array\n",
    "image = io.imread(file_name )\n",
    "# Run the HOG face detector on the image data.\n",
    "# The result will be the bounding boxes of the faces in our image.\n",
    "detected_faces = face_detector(image, 1)\n",
    "\n",
    "print(\"I found {} faces in the file {}\".format(len(detected_faces), file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to create image_window, you must make sure there you have set up X11 in your laptop to show the image imread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a window on the desktop showing the image\n",
    "win.set_image(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Face #0 found at Left: 91 Top: 246 Right: 553 Bottom: 708\n"
     ]
    }
   ],
   "source": [
    "\t# Detected faces are returned as an object with the coordinates \n",
    "\t# of the top, left, right and bottom edges\n",
    "    \n",
    "    # Loop through each face we found in the image\n",
    "for i, face_rect in enumerate(detected_faces):\n",
    "    print(\"- Face #{} found at Left: {} Top: {} Right: {} Bottom: {}\".format(i, face_rect.left(), face_rect.top(), face_rect.right(), face_rect.bottom()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detect result is shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t# Draw a box around each face we found\n",
    "\twin.add_overlay(face_rect)\n",
    "\t        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until the user hits <enter> to close the window\t        \n",
    "dlib.hit_enter_to_continue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 68 landmark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Humans can easily recognize that both images are the same people, but the computer thinks these two pictures are two completely different people. To solve this, we will try to distort each image so that the eyes and lips are always in the sample place in the image. This will make it easier to compare the differences between faces in the next steps. To do this, we'll use an algorithm called face landmark estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea of this algorithm is to find the specific points. Usually, we find 68 common points(known as landmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dlib\n",
    "import os\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a muture 68_face_landmarks model we could use which uses the principle of ERTï¼ˆensemble of regression trees.That is, a regression tree method based on gradients to improve learning. The algorithm uses cascading regression factors. First, a series of calibrated face images are used as the training set. Then a model is generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When an image is obtained, the algorithm generates an initial shape by first estimating a rough feature point location, and then using the gradient boosting algorithm to reduce the sum of the squared errors of the initial shape and ground truth. The least squares method was used to minimize the error and a cascade regression factor for each stage was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "predictor_path = current_path + \"/model/shape_predictor_68_face_landmarks (1).dat\"\n",
    "#predictor_model = \"shape_predictor_68_face_landmarks (1).dat\"\n",
    "# Create a HOG face detector using the built-in dlib class\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "face_pose_predictor = dlib.shape_predictor(predictor_path)\n",
    "win = dlib.image_window()\n",
    "# Take the image file name from the command line\n",
    "file_name = '/Users/mac/7390/Final/faces/Emma.jpg'\n",
    "# Load the image\n",
    "image = io.imread(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 faces in the image file /Users/mac/7390/Final/faces/Emma.jpg\n"
     ]
    }
   ],
   "source": [
    "# Run the HOG face detector on the image data\n",
    "detected_faces = face_detector(image, 1)\n",
    "print(\"Found {} faces in the image file {}\".format(len(detected_faces), file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the desktop window with the image\n",
    "win.set_image(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tasks above are similar to those in step1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Face #0 found at Left: 91 Top: 246 Right: 553 Bottom: 708\n",
      "Part 0: (190, 460), Part 1: (187, 500) ...\n"
     ]
    }
   ],
   "source": [
    "# Loop through each face we found in the image\n",
    "for i, face_rect in enumerate(detected_faces):\n",
    "\n",
    "\t# Detected faces are returned as an object with the coordinates \n",
    "\t# of the top, left, right and bottom edges\n",
    "    print(\"- Face #{} found at Left: {} Top: {} Right: {} Bottom: {}\".format(i, face_rect.left(), face_rect.top(), face_rect.right(), face_rect.bottom()))\n",
    "pose_landmarks = face_pose_predictor(image, face_rect)\n",
    "print(\"Part 0: {}, Part 1: {} ...\".format(pose_landmarks.part(0),\n",
    "                                                  pose_landmarks.part(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a box around each face we found\n",
    "win.add_overlay(face_rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pose_landmarks = face_pose_predictor(image, face_rect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every landmarks within range 68 has their specific meaning, like point 30 represents the tip of nose, and similarly, the landmark 27 represents the root of the nose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 223)\n",
      "(82, 173)\n",
      "(81, 322)\n",
      "(47, 165)\n",
      "(74, 173)\n",
      "(155, 181)\n",
      "(117, 180)\n",
      "(76, 265)\n",
      "(58, 259)\n",
      "(126, 266)\n",
      "(38, 179)\n",
      "(236, 183)\n"
     ]
    }
   ],
   "source": [
    "# tip of the nose  30\n",
    "# root of the nose 27  \n",
    "# chin  8  \n",
    "# left eye outer corner 36  \n",
    "# left eye inner corner 39  \n",
    "# right eye outer corner 45  \n",
    "# right eye inner corner 42  \n",
    "# middle of mouth   66  \n",
    "# mouth left corner   48  \n",
    "# mouth right corner  54  \n",
    "# left face outer 0  \n",
    "# right face outer 16  \n",
    "#pose_landmarks.part(8),pose_landmarks.part(36),pose_landmarks.part(39),pose_landmarks.part(45),pose_landmarks.part(42),pose_landmarks.part(66),pose_landmarks.part(48),pose_landmarks.part(54),pose_landmarks.part(0),pose_landmarks.part(16)\n",
    "print(pose_landmarks.part(30))\n",
    "print(pose_landmarks.part(27))\n",
    "print(pose_landmarks.part(8))\n",
    "print(pose_landmarks.part(36))\n",
    "print(pose_landmarks.part(39))\n",
    "print(pose_landmarks.part(45))\n",
    "print(pose_landmarks.part(42))\n",
    "print(pose_landmarks.part(66))\n",
    "print(pose_landmarks.part(48))\n",
    "print(pose_landmarks.part(54))\n",
    "print(pose_landmarks.part(0))\n",
    "print(pose_landmarks.part(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the face landmarks on the screen.\n",
    "win.add_overlay(pose_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlib.hit_enter_to_continue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picture Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we get a face, it could be front face but it could also be a side face. So if we use the landmarks directly gotten from 68 landmarks model, it will affect the training in following step. Because of this, we should try to twist the landmarks in order to revise some image in the circumatance like side face or any other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import openface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "predictor_path = current_path + \"/model/shape_predictor_68_face_landmarks (1).dat\"\n",
    "# Create a HOG face detector using the built-in dlib class\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "face_pose_predictor = dlib.shape_predictor(predictor_path)\n",
    "face_aligner = openface.AlignDlib(predictor_path)\n",
    "# Take the image file name from the command line\n",
    "file_name = '/Users/mac/7390/Final/faces/Emma.jpg'\n",
    "# Load the image\n",
    "image = cv2.imread(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 faces in the image file /Users/mac/7390/Final/faces/Emma.jpg\n"
     ]
    }
   ],
   "source": [
    "# Run the HOG face detector on the image data\n",
    "detected_faces = face_detector(image, 1)\n",
    "print(\"Found {} faces in the image file {}\".format(len(detected_faces), file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The face_aligner.align is the tool to revise the landmarks got from 68_landmarks_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Face #0 found at Left: 91 Top: 246 Right: 553 Bottom: 708\n"
     ]
    }
   ],
   "source": [
    "# Loop through each face we found in the image\n",
    "for i, face_rect in enumerate(detected_faces):\n",
    "\n",
    "\t# Detected faces are returned as an object with the coordinates \n",
    "\t# of the top, left, right and bottom edges\n",
    "\tprint(\"- Face #{} found at Left: {} Top: {} Right: {} Bottom: {}\".format(i, face_rect.left(), face_rect.top(), face_rect.right(), face_rect.bottom()))\n",
    "\n",
    "\t# Get the the face's pose\n",
    "\tpose_landmarks = face_pose_predictor(image, face_rect)\n",
    "\n",
    "\t# Use openface to calculate and perform the face alignment\n",
    "\talignedFace = face_aligner.align(534, image, face_rect, landmarkIndices=openface.AlignDlib.OUTER_EYES_AND_NOSE)\n",
    "\n",
    "\t# Save the aligned image to a file\n",
    "\tcv2.imwrite(\"aligned_face_{}.jpg\".format(i), alignedFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright <2018> <Haoran Han & Lintong Yang>\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
